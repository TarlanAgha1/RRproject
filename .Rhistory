remotes::install_version(package_version_install)
}
}
mapply(check_and_install, names(packages_version), packages_version)
url<-"https://raw.githubusercontent.com/WojciechMisiura/RRproject/main/bank.csv"
bank<-read_csv(url)
# Brief verification of dataset to determine whether there are any missing values
bank %>% summarize(across(everything(), ~sum(is.na(.))))
summary(bank)
g_age <- ggplot(bank, aes(x = factor(0), y = age)) +
geom_boxplot() +
labs(x = NULL, y = "Age") +
theme(axis.title.x = element_blank())
g_age
# Create a distribution plot for 'age'
g_age_dist <- ggplot(bank, aes(x = age)) +
geom_histogram(bins = 100, fill = "blue", color = "black") +
ggtitle("Distribution of Age")
g_age_dist
bank_above_70 <- bank %>%
filter(age > 70)
print(bank_above_70)
# Create a boxplot for 'duration'
g_duration <- ggplot(bank, aes(x = factor(0), y = duration)) +
geom_boxplot() +
labs(x = NULL, y = "Duration") +
theme(axis.title.x = element_blank())
g_duration
# Create a distribution plot for 'duration'
g_duration_dist <- ggplot(bank, aes(x = duration)) +
geom_histogram(bins = 100, fill = "red", color = "black") +
ggtitle("Distribution of Duration")
g_duration_dist
# Copy data for processing
bank_data <- bank
jobs <- c('management', 'blue-collar', 'technician', 'admin.', 'services',
'retired', 'self-employed', 'student', 'unemployed', 'entrepreneur','housemaid', 'unknown')
for (j in jobs) {
count <- sum(bank_data$deposit == "yes" & bank_data$job == j)
cat(sprintf("%-15s : %5d\n", j, count))}
# Filter data where deposit is "yes"
bank_data_filtered <- bank_data %>%
filter(deposit == "yes")
p <- ggplot(bank_data_filtered, aes(x = age)) +
geom_histogram(bins = 10, fill = "skyblue", color = "black") +
facet_wrap(~ job, scales = "free_y") +
labs(title = "Age Distribution by Job for Deposits Marked 'Yes'",
x = "Age",
y = "Count") +
theme_minimal()
print(p)
table(bank_data$job)
# 'white-collar' category includes job types 'management' and 'admin.'
bank_data$job[bank_data$job %in% c('management', 'admin.')] <- 'white-collar'
# 'pink-collar' category includes job types 'services' and 'housemaid'
bank_data$job[bank_data$job %in% c('services', 'housemaid')] <- 'pink-collar'
# 'other' category includes job types 'retired', 'student', 'unemployed', and 'unknown'
bank_data$job[bank_data$job %in% c('retired', 'student', 'unemployed', 'unknown')] <- 'other'
table(bank_data$job)
# Convert the 'poutcome' column in the 'bank_data' dataframe to character type
bank_data$poutcome <- as.character(bank_data$poutcome)
# Replace any occurrences of "other" in the 'poutcome' column with "unknown"
bank_data$poutcome[bank_data$poutcome == "other"] <- "unknown"
# Display the frequency table of the 'poutcome' column
table(bank_data$poutcome)
bank_data <- select(bank_data, -contact)
# Convert categorical variables to binary indicators
bank_data$default_cat <- as.integer(bank_data$default == "yes")
bank_data$housing_cat <- as.integer(bank_data$housing == "yes")
bank_data$loan_cat <- as.integer(bank_data$loan == "yes")
# Remove original categorical variables from the dataset
bank_data <- select(bank_data, -c(default, housing, loan))
bank_data <- select(bank_data, -c(month, day))
bank_data$deposit_cat <- as.integer(bank_data$deposit == "yes")
bank_data <- select(bank_data, -deposit)
cat("Customers that have not been contacted before:", sum(bank_data$pdays == -1), "\n")
cat("Maximum values on pdays:", max(bank_data$pdays), "\n")
bank_data$pdays[bank_data$pdays == -1] <- 10000
bank_data$recent_pdays <- ifelse(bank_data$pdays > 0, 1/bank_data$pdays, 1/bank_data$pdays)
bank_data <- select(bank_data, -pdays)
tail(bank_data)
bank_with_dummies <- dummy_cols(bank_data, select_columns = c('job', 'marital', 'education', 'poutcome'),
remove_selected_columns = TRUE)
head(bank_with_dummies)
print(dim(bank_with_dummies))
summary(bank_with_dummies)
ggplot(bank_with_dummies, aes(x = age, y = balance)) +
geom_point(alpha = 0.5) +
labs(title = "Scatterplot of Age vs. Balance",
subtitle = "Across all ages, majority of people have savings of less than 20000",
x = "Age", y = "Balance") +
theme_minimal()
ggplot(bank_with_dummies, aes(x = duration)) +
geom_histogram(data = subset(bank_with_dummies, poutcome_success == 1), fill = "blue", bins = 30) +
labs(title = "Histogram of Duration for 'poutcome_success'",
x = "Duration", y = "Count") +
theme_minimal()
bank_with_dummies %>%
filter(deposit_cat == 1) %>%
summary()
sum(bank_with_dummies$deposit_cat == 1 & bank_with_dummies$loan_cat == 1 & bank_with_dummies$housing_cat == 1)
sum(bank_with_dummies$deposit_cat == 1 & bank_with_dummies$default_cat == 1)
ggplot(data = bank_data, aes(x = job, y = deposit_cat, fill = job)) +
geom_bar(stat = "summary", fun = mean) +
labs(title = "Average Deposit Category by Job", x = "Job Category", y = "Average Deposit Category") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(data = bank_data, aes(x = poutcome, y = duration, fill = poutcome)) +
geom_bar(stat = "summary", fun = mean) +
labs(title = "Average Duration by Outcome", x = "Outcome", y = "Average Duration") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
bankcl <- bank_with_dummies
corr <- cor(bankcl, use = "complete.obs")
print(corr)
corrplot(corr, method = "color", type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45,
col = colorRampPalette(c(brewer.pal(10, "RdBu")[10:1]))(200),
title = "Heatmap of Correlation Matrix",
cl.lim = c(-0.3, 0.3))
# Extract the deposit_cat column (the dependent variable)
corr_deposit <- as.data.frame(corr['deposit_cat', , drop = FALSE])
# Remove the row corresponding to 'deposit_cat' itself if included
corr_deposit <- corr_deposit[-which(rownames(corr_deposit) == 'deposit_cat'), ]
# Sort the remaining data frame in descending order based on the values in deposit_cat
corr_deposit <- corr_deposit[order(corr_deposit$deposit_cat, decreasing = TRUE), ]
# Set the seed for reproducibility
set.seed(50)
# Extract the 'deposit_cat' column as the label
label <- bankcl$deposit_cat
# Remove the 'deposit_cat' column from the dataset
data_drop_deposite <- bankcl[, !names(bankcl) %in% 'deposit_cat']
# Create a training set by randomly selecting 80% of the data
index_train <- createDataPartition(label, p = 0.8, list = FALSE)
data_train <- data_drop_deposite[index_train, ]
label_train <- label[index_train]
# Create a test set by selecting the remaining data
data_test <- data_drop_deposite[-index_train, ]
label_test <- label[-index_train]
train_and_evaluate <- function(depth) {
model <- rpart(formula = deposit_cat ~ ., data = bankcl, method = "class",
control = rpart.control(maxdepth = depth, usesurrogate = 0, xval = 10))
train_pred <- predict(model, data_train, type = "class")
test_pred <- predict(model, data_test, type = "class")
train_accuracy <- sum(train_pred == label_train) / length(label_train)
test_accuracy <- sum(test_pred == label_test) / length(label_test)
cat(sprintf("Depth %d: Training score: %f, Testing score: %f\n", depth, train_accuracy, test_accuracy))
return(c(train = train_accuracy, test = test_accuracy))
}
# Create an empty list to store the scores
scores <- list()
# Define the depth levels for training and testing
depth_levels <- c(1, 2, 3, 4, 6)
names(depth_levels) <- c("max", "2", "3", "4", "6")
# Iterate over each depth level and train and evaluate the model
for (depth in depth_levels) {
result <- train_and_evaluate(depth)
scores[[as.character(depth)]] <- list(train = result[1], test = result[2])
}
# Print the scores in a formatted table
cat(sprintf('%-10s %-20s %-20s\n', 'depth', 'Training score', 'Testing score'))
cat(sprintf('%-10s %-20s %-20s\n', '-----', '--------------', '-------------'))
for (depth in c("2", "3", "4", "6", "max")) {
cat(sprintf('%-1s %-25.2f %-20.2f\n', depth, scores[[depth]]$train, scores[[depth]]$test))
}
dt2 <- rpart(label_train ~ ., data = data_train, method = "class", control = rpart.control(maxdepth = 2))
fi <- dt2$variable.importance
features <- names(fi)
l <- length(features)
for (i in 1:l) {
cat(sprintf('%-20s %3f\n', features[i], fi[i]))
}
cat(sprintf("Mean duration   : %f\n", mean(data_drop_deposite$duration, na.rm = TRUE)))
cat(sprintf("Maximum duration: %d\n", max(data_drop_deposite$duration, na.rm = TRUE)))
cat(sprintf("Minimum duration: %d\n", min(data_drop_deposite$duration, na.rm = TRUE)))
new_data_371 <- data.frame(matrix(0, nrow = 1, ncol = length(names(data_drop_deposite))))
names(new_data_371) <- names(data_drop_deposite)
new_data_371$duration <- 371  # Set duration for prediction
new_data_3881 <- data.frame(matrix(0, nrow = 1, ncol = length(names(data_drop_deposite))))
names(new_data_3881) <- names(data_drop_deposite)
new_data_3881$duration <- 3881  # Set duration for prediction
probabilities_371 <- predict(dt2, new_data_371, type = "prob")
probabilities_3881 <- predict(dt2, new_data_3881, type = "prob")
class_371 <- predict(dt2, new_data_371, type = "class")
class_3881 <- predict(dt2, new_data_3881, type = "class")
cat("Probabilities with duration 371 sec:\n")
print(probabilities_371)
cat("Predicted class with duration 371 sec:\n")
print(class_371)
cat("Probabilities with duration 3881 sec:\n")
print(probabilities_3881)
cat("Predicted class with duration 3881 sec:\n")
print(class_3881)
specific_row <- data_drop_deposite[986, ]
probability_prediction <- predict(dt2, specific_row, type = "prob")
print(probability_prediction)
preds <- predict(dt2, data_test, type = "class")
levels_set <- union(levels(factor(label_test)), levels(factor(preds)))
preds_factor <- factor(preds, levels = levels_set)
label_test_factor <- factor(label_test, levels = levels_set)
accuracy_matrix <- confusionMatrix(preds_factor, label_test_factor)
accuracy <- accuracy_matrix$overall['Accuracy']
cat("\nAccuracy score: \n", accuracy)
probs <- predict(dt2, data_test, type = "prob")
positive_probs <- probs[, 2]
auc_value <- roc(label_test, positive_probs)$auc
cat("\nArea Under Curve: \n", auc_value)
# Fit a Gradient Boosting model
gbm_model <- gbm(deposit_cat ~ .,
data = bank_with_dummies[index_train, ],
distribution = "bernoulli",
n.trees = 100,
interaction.depth = 4,
shrinkage = 0.01,
cv.folds = 5,
n.minobsinnode = 10,
verbose = TRUE)
library(gbm)
# Fit a Gradient Boosting model
gbm_model <- gbm(deposit_cat ~ .,
data = bank_with_dummies[index_train, ],
distribution = "bernoulli",
n.trees = 100,
interaction.depth = 4,
shrinkage = 0.01,
cv.folds = 5,
n.minobsinnode = 10,
verbose = TRUE)
# Summary of the gbm model
summary(gbm_model)
# Cross-validated error plot
gbm.perf(gbm_model, method = "cv")
# Make predictions on the test set
gbm_predictions_prob <- predict(gbm_model, data_test, n.trees = gbm_model$n.trees, type = "response")
# Convert probabilities to binary outcome based on a threshold (e.g., 0.5)
gbm_predictions <- ifelse(gbm_predictions_prob > 0.5, 1, 0)
# Evaluate model accuracy
gbm_accuracy <- sum(gbm_predictions == label_test) / length(label_test)
cat(sprintf("GBM Model Accuracy: %f\n", gbm_accuracy))
# Calculate the AUC
gbm_roc <- roc(label_test, gbm_predictions_prob)
cat(sprintf("Area Under Curve for GBM: %f\n", gbm_roc$auc))
packages_version <- c(
"readr" = "2.1.4",
"dplyr" = "1.1.2",
"ggplot2" = "3.4.2",
"fastDummies" = "1.7.3",
"rpart" = "4.1.23",
"caret" = "6.0.94",
"rpart.plot" = "3.1.2",
"pROC" = "1.18.5",
"corrplot" = "0.92",
"RColorBrewer" = "1.1.3",
"tibble" = "3.2.1",
"rpart" = "4.1.23",
'gbm' = '2.1.8'
)
check_and_install <- function(package, version) {
if (!require(package, character.only = TRUE)) {
package_version_install <- paste0(package, "@", version)
remotes::install_version(package_version_install)
}
}
mapply(check_and_install, names(packages_version), packages_version)
url<-"https://raw.githubusercontent.com/WojciechMisiura/RRproject/main/bank.csv"
bank<-read_csv(url)
# Brief verification of dataset to determine whether there are any missing values
bank %>% summarize(across(everything(), ~sum(is.na(.))))
summary(bank)
g_age <- ggplot(bank, aes(x = factor(0), y = age)) +
geom_boxplot() +
labs(x = NULL, y = "Age") +
theme(axis.title.x = element_blank())
g_age
# Create a distribution plot for 'age'
g_age_dist <- ggplot(bank, aes(x = age)) +
geom_histogram(bins = 100, fill = "blue", color = "black") +
ggtitle("Distribution of Age")
g_age_dist
bank_above_70 <- bank %>%
filter(age > 70)
print(bank_above_70)
# Create a boxplot for 'duration'
g_duration <- ggplot(bank, aes(x = factor(0), y = duration)) +
geom_boxplot() +
labs(x = NULL, y = "Duration") +
theme(axis.title.x = element_blank())
g_duration
# Create a distribution plot for 'duration'
g_duration_dist <- ggplot(bank, aes(x = duration)) +
geom_histogram(bins = 100, fill = "red", color = "black") +
ggtitle("Distribution of Duration")
g_duration_dist
# Copy data for processing
bank_data <- bank
jobs <- c('management', 'blue-collar', 'technician', 'admin.', 'services',
'retired', 'self-employed', 'student', 'unemployed', 'entrepreneur','housemaid', 'unknown')
for (j in jobs) {
count <- sum(bank_data$deposit == "yes" & bank_data$job == j)
cat(sprintf("%-15s : %5d\n", j, count))}
# Filter data where deposit is "yes"
bank_data_filtered <- bank_data %>%
filter(deposit == "yes")
p <- ggplot(bank_data_filtered, aes(x = age)) +
geom_histogram(bins = 10, fill = "skyblue", color = "black") +
facet_wrap(~ job, scales = "free_y") +
labs(title = "Age Distribution by Job for Deposits Marked 'Yes'",
x = "Age",
y = "Count") +
theme_minimal()
print(p)
table(bank_data$job)
# 'white-collar' category includes job types 'management' and 'admin.'
bank_data$job[bank_data$job %in% c('management', 'admin.')] <- 'white-collar'
# 'pink-collar' category includes job types 'services' and 'housemaid'
bank_data$job[bank_data$job %in% c('services', 'housemaid')] <- 'pink-collar'
# 'other' category includes job types 'retired', 'student', 'unemployed', and 'unknown'
bank_data$job[bank_data$job %in% c('retired', 'student', 'unemployed', 'unknown')] <- 'other'
table(bank_data$job)
# Convert the 'poutcome' column in the 'bank_data' dataframe to character type
bank_data$poutcome <- as.character(bank_data$poutcome)
# Replace any occurrences of "other" in the 'poutcome' column with "unknown"
bank_data$poutcome[bank_data$poutcome == "other"] <- "unknown"
# Display the frequency table of the 'poutcome' column
table(bank_data$poutcome)
bank_data <- select(bank_data, -contact)
# Convert categorical variables to binary indicators
bank_data$default_cat <- as.integer(bank_data$default == "yes")
bank_data$housing_cat <- as.integer(bank_data$housing == "yes")
bank_data$loan_cat <- as.integer(bank_data$loan == "yes")
# Remove original categorical variables from the dataset
bank_data <- select(bank_data, -c(default, housing, loan))
bank_data <- select(bank_data, -c(month, day))
bank_data$deposit_cat <- as.integer(bank_data$deposit == "yes")
bank_data <- select(bank_data, -deposit)
cat("Customers that have not been contacted before:", sum(bank_data$pdays == -1), "\n")
cat("Maximum values on pdays:", max(bank_data$pdays), "\n")
bank_data$pdays[bank_data$pdays == -1] <- 10000
bank_data$recent_pdays <- ifelse(bank_data$pdays > 0, 1/bank_data$pdays, 1/bank_data$pdays)
bank_data <- select(bank_data, -pdays)
tail(bank_data)
bank_with_dummies <- dummy_cols(bank_data, select_columns = c('job', 'marital', 'education', 'poutcome'),
remove_selected_columns = TRUE)
head(bank_with_dummies)
print(dim(bank_with_dummies))
summary(bank_with_dummies)
ggplot(bank_with_dummies, aes(x = age, y = balance)) +
geom_point(alpha = 0.5) +
labs(title = "Scatterplot of Age vs. Balance",
subtitle = "Across all ages, majority of people have savings of less than 20000",
x = "Age", y = "Balance") +
theme_minimal()
ggplot(bank_with_dummies, aes(x = duration)) +
geom_histogram(data = subset(bank_with_dummies, poutcome_success == 1), fill = "blue", bins = 30) +
labs(title = "Histogram of Duration for 'poutcome_success'",
x = "Duration", y = "Count") +
theme_minimal()
bank_with_dummies %>%
filter(deposit_cat == 1) %>%
summary()
sum(bank_with_dummies$deposit_cat == 1 & bank_with_dummies$loan_cat == 1 & bank_with_dummies$housing_cat == 1)
sum(bank_with_dummies$deposit_cat == 1 & bank_with_dummies$default_cat == 1)
ggplot(data = bank_data, aes(x = job, y = deposit_cat, fill = job)) +
geom_bar(stat = "summary", fun = mean) +
labs(title = "Average Deposit Category by Job", x = "Job Category", y = "Average Deposit Category") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(data = bank_data, aes(x = poutcome, y = duration, fill = poutcome)) +
geom_bar(stat = "summary", fun = mean) +
labs(title = "Average Duration by Outcome", x = "Outcome", y = "Average Duration") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
bankcl <- bank_with_dummies
corr <- cor(bankcl, use = "complete.obs")
print(corr)
corrplot(corr, method = "color", type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45,
col = colorRampPalette(c(brewer.pal(10, "RdBu")[10:1]))(200),
title = "Heatmap of Correlation Matrix",
cl.lim = c(-0.3, 0.3))
# Extract the deposit_cat column (the dependent variable)
corr_deposit <- as.data.frame(corr['deposit_cat', , drop = FALSE])
# Remove the row corresponding to 'deposit_cat' itself if included
corr_deposit <- corr_deposit[-which(rownames(corr_deposit) == 'deposit_cat'), ]
# Sort the remaining data frame in descending order based on the values in deposit_cat
corr_deposit <- corr_deposit[order(corr_deposit$deposit_cat, decreasing = TRUE), ]
# Set the seed for reproducibility
set.seed(50)
# Extract the 'deposit_cat' column as the label
label <- bankcl$deposit_cat
# Remove the 'deposit_cat' column from the dataset
data_drop_deposite <- bankcl[, !names(bankcl) %in% 'deposit_cat']
# Create a training set by randomly selecting 80% of the data
index_train <- createDataPartition(label, p = 0.8, list = FALSE)
data_train <- data_drop_deposite[index_train, ]
label_train <- label[index_train]
# Create a test set by selecting the remaining data
data_test <- data_drop_deposite[-index_train, ]
label_test <- label[-index_train]
train_and_evaluate <- function(depth) {
model <- rpart(formula = deposit_cat ~ ., data = bankcl, method = "class",
control = rpart.control(maxdepth = depth, usesurrogate = 0, xval = 10))
train_pred <- predict(model, data_train, type = "class")
test_pred <- predict(model, data_test, type = "class")
train_accuracy <- sum(train_pred == label_train) / length(label_train)
test_accuracy <- sum(test_pred == label_test) / length(label_test)
cat(sprintf("Depth %d: Training score: %f, Testing score: %f\n", depth, train_accuracy, test_accuracy))
return(c(train = train_accuracy, test = test_accuracy))
}
# Create an empty list to store the scores
scores <- list()
# Define the depth levels for training and testing
depth_levels <- c(1, 2, 3, 4, 6)
names(depth_levels) <- c("max", "2", "3", "4", "6")
# Iterate over each depth level and train and evaluate the model
for (depth in depth_levels) {
result <- train_and_evaluate(depth)
scores[[as.character(depth)]] <- list(train = result[1], test = result[2])
}
# Print the scores in a formatted table
cat(sprintf('%-10s %-20s %-20s\n', 'depth', 'Training score', 'Testing score'))
cat(sprintf('%-10s %-20s %-20s\n', '-----', '--------------', '-------------'))
for (depth in c("2", "3", "4", "6", "max")) {
cat(sprintf('%-1s %-25.2f %-20.2f\n', depth, scores[[depth]]$train, scores[[depth]]$test))
}
dt2 <- rpart(label_train ~ ., data = data_train, method = "class", control = rpart.control(maxdepth = 2))
fi <- dt2$variable.importance
features <- names(fi)
l <- length(features)
for (i in 1:l) {
cat(sprintf('%-20s %3f\n', features[i], fi[i]))
}
cat(sprintf("Mean duration   : %f\n", mean(data_drop_deposite$duration, na.rm = TRUE)))
cat(sprintf("Maximum duration: %d\n", max(data_drop_deposite$duration, na.rm = TRUE)))
cat(sprintf("Minimum duration: %d\n", min(data_drop_deposite$duration, na.rm = TRUE)))
new_data_371 <- data.frame(matrix(0, nrow = 1, ncol = length(names(data_drop_deposite))))
names(new_data_371) <- names(data_drop_deposite)
new_data_371$duration <- 371  # Set duration for prediction
new_data_3881 <- data.frame(matrix(0, nrow = 1, ncol = length(names(data_drop_deposite))))
names(new_data_3881) <- names(data_drop_deposite)
new_data_3881$duration <- 3881  # Set duration for prediction
probabilities_371 <- predict(dt2, new_data_371, type = "prob")
probabilities_3881 <- predict(dt2, new_data_3881, type = "prob")
class_371 <- predict(dt2, new_data_371, type = "class")
class_3881 <- predict(dt2, new_data_3881, type = "class")
cat("Probabilities with duration 371 sec:\n")
print(probabilities_371)
cat("Predicted class with duration 371 sec:\n")
print(class_371)
cat("Probabilities with duration 3881 sec:\n")
print(probabilities_3881)
cat("Predicted class with duration 3881 sec:\n")
print(class_3881)
specific_row <- data_drop_deposite[986, ]
probability_prediction <- predict(dt2, specific_row, type = "prob")
print(probability_prediction)
preds <- predict(dt2, data_test, type = "class")
levels_set <- union(levels(factor(label_test)), levels(factor(preds)))
preds_factor <- factor(preds, levels = levels_set)
label_test_factor <- factor(label_test, levels = levels_set)
accuracy_matrix <- confusionMatrix(preds_factor, label_test_factor)
accuracy <- accuracy_matrix$overall['Accuracy']
cat("\nAccuracy score: \n", accuracy)
probs <- predict(dt2, data_test, type = "prob")
positive_probs <- probs[, 2]
auc_value <- roc(label_test, positive_probs)$auc
cat("\nArea Under Curve: \n", auc_value)
# Fit a Gradient Boosting model
gbm_model <- gbm(deposit_cat ~ .,
data = bank_with_dummies[index_train, ],
distribution = "bernoulli",
n.trees = 100,
interaction.depth = 4,
shrinkage = 0.01,
cv.folds = 5,
n.minobsinnode = 10,
verbose = TRUE)
# Summary of the gbm model
summary(gbm_model)
# Cross-validated error plot
gbm.perf(gbm_model, method = "cv")
# Make predictions on the test set
gbm_predictions_prob <- predict(gbm_model, data_test, n.trees = gbm_model$n.trees, type = "response")
# Convert probabilities to binary outcome based on a threshold (e.g., 0.5)
gbm_predictions <- ifelse(gbm_predictions_prob > 0.5, 1, 0)
# Evaluate model accuracy
gbm_accuracy <- sum(gbm_predictions == label_test) / length(label_test)
cat(sprintf("GBM Model Accuracy: %f\n", gbm_accuracy))
# Calculate the AUC
gbm_roc <- roc(label_test, gbm_predictions_prob)
cat(sprintf("Area Under Curve for GBM: %f\n", gbm_roc$auc))
new_data_371 <- data.frame(matrix(0, nrow = 1, ncol = length(names(data_test))))
names(new_data_371) <- names(data_test)
new_data_371$duration <- 371
new_data_3881 <- data.frame(matrix(0, nrow = 1, ncol = length(names(data_test))))
names(new_data_3881) <- names(data_test)
new_data_3881$duration <- 3881
# Predict probabilities using the Gradient Boosting Model
probabilities_371 <- predict(gbm_model, new_data_371, n.trees = gbm_model$n.trees, type = "response")
probabilities_3881 <- predict(gbm_model, new_data_3881, n.trees = gbm_model$n.trees, type = "response")
# Determine the class based on a threshold (typically 0.5 for binary classification)
class_371 <- ifelse(probabilities_371 > 0.5, 1, 0)
class_3881 <- ifelse(probabilities_3881 > 0.5, 1, 0)
# Print probabilities and predicted classes
cat("Probabilities with duration 371 sec:\n")
print(probabilities_371)
cat("Predicted class with duration 371 sec:\n")
print(class_371)
cat("Probabilities with duration 3881 sec:\n")
print(probabilities_3881)
cat("Predicted class with duration 3881 sec:\n")
print(class_3881)
